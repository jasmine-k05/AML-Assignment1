# -*- coding: utf-8 -*-
"""Source  Code _ Naive_Bayes

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KrU2CZbsfoC9rdgd7a6eaKssqr_DlaM_
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split  # Import train_test_split
from sklearn.naive_bayes import GaussianNB  # Import GaussianNB
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from google.colab import drive
import joblib

# Unmount and remount Google Drive
drive.flush_and_unmount()
drive.mount('/content/gdrive', force_remount=True)

# Verify the file path
!ls '/content/gdrive/MyDrive/AML'

# Load dataset from Google Drive
file_path = '/content/gdrive/MyDrive/AML /Crop_recommendation.csv'
df = pd.read_csv(file_path)

# Display the first 2 rows
print(df.head(2))

# Visualize class distribution
plt.figure(figsize=(12, 8))
sns.countplot(y=df['label'], order=df['label'].value_counts().index)
plt.title('Class Distribution of Crops', fontsize=16)
plt.xlabel('Number of Samples', fontsize=14)
plt.ylabel('Crop', fontsize=14)
plt.show()

# Data Preprocessing
X = df.drop('label', axis=1)
y = df['label']

# Encode labels
le = LabelEncoder()
y = le.fit_transform(y)

# Handle imbalanced data using SMOTE
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a GaussianNB (Naive Bayes) with Laplace smoothing
model = GaussianNB(var_smoothing=1e-9)  # Laplace smoothing using the var_smoothing parameter
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)

# Decode the predictions back to original labels
y_pred_labels = le.inverse_transform(y_pred)
y_test_labels = le.inverse_transform(y_test)

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test_labels, y_pred_labels)
class_report = classification_report(y_test_labels, y_pred_labels)

print("Accuracy:", accuracy)
print("Confusion Matrix:\n", conf_matrix)
print("Classification Report:\n", class_report)

# Plot the confusion matrix with labels
plt.figure(figsize=(12, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Save the model for future use
joblib.dump(model, 'naive_bayes_model.pkl')